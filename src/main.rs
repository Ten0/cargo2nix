#![forbid(unsafe_code)]

use std::{
    collections::{BTreeMap, BTreeSet, HashMap, HashSet},
    fs,
    io::{self, BufRead, Write},
    path::PathBuf,
};

use {
    anyhow::{anyhow, Context, Result},
    clap::{Command, CommandFactory, Parser, ValueHint},
    clap_complete::{generate, Generator, Shell},
    colorify::colorify,
    semver::{Version, VersionReq},
    sha2::{Digest, Sha256},
    tera::Tera,
};

use crate::{expr::BoolExpr, template::BuildPlan};

mod expr;
mod manifest;
mod platform;
mod template;

type Feature<'a> = &'a str;
type PackageName<'a> = &'a str;
type RootFeature<'a> = (PackageName<'a>, Feature<'a>);

const VERSION_ATTRIBUTE_NAME: &str = "cargo2nixVersion";

#[derive(Parser, Debug, PartialEq)]
#[command(about, author, long_about = None, version)]
/// Granular caching, development shell, Nix & Rust integration
struct Opt {
    /// Optional workspace directory (default value: ./)
    #[arg(value_name = "WORKSPACE_DIRECTORY", value_hint = ValueHint::DirPath)]
    workspace_directory: Option<PathBuf>,
    /// Generate a SHELL completion script
    #[arg(long = "completions", value_enum)]
    generator: Option<Shell>,
    /// Output to filepath (default value: ./Cargo.nix)
    #[arg(conflicts_with = "stdout", long, short, value_name = "FILEPATH", value_hint = ValueHint::FilePath)]
    file: Option<PathBuf>,
    /// Overwrite existing output filepath without prompting
    #[arg(action, long, short)]
    overwrite: bool,
    /// Don't attempt to update the lockfile
    #[arg(action, long, short, value_name = "LOCKED")]
    locked: bool,
    /// Output to stdout
    #[arg(conflicts_with = "file", action, long, short)]
    stdout: bool,
}

fn main() -> std::io::Result<()> {
    let opt = Opt::parse();

    if let Some(generator) = opt.generator {
        let mut cmd = Opt::command();
        eprintln!("Generating completion file for {:?}...", generator);
        print_completions(generator, &mut cmd);
        std::process::exit(0);
    }

    let workspace_directory = opt
        .workspace_directory
        .unwrap_or(std::env::current_dir()?)
        .canonicalize()?;
    let file = opt.file.unwrap_or(PathBuf::from("./Cargo.nix"));

    let rendered = generate_cargo_nix(&workspace_directory, opt.locked)
        .expect("Error generating nix expressions");

    if opt.stdout {
        write_to_stdout(&rendered).expect("Error writing to stdout");
    } else {
        write_to_file(&file, &rendered, &opt.overwrite).expect("Error writing to file");
    }

    Ok(())
}

fn print_completions<G: Generator>(gen: G, cmd: &mut Command) {
    generate(gen, cmd, cmd.get_name().to_string(), &mut io::stdout());
}

fn version() -> Version {
    // Since `CARGO_PKG_VERSION` is provided by Cargo itself, which uses the same `semver` crate to
    // parse version strings, the `unwrap()` below should never fail.
    Version::parse(env!("CARGO_PKG_VERSION")).unwrap()
}

fn read_version_attribute(path: &PathBuf) -> Result<Version> {
    let file = fs::File::open(path).context(format!("Couldn't open file {}", path.display()))?;
    io::BufReader::new(file)
        .lines()
        .filter_map(|line| line.ok())
        .find(|line| line.trim_start().starts_with(VERSION_ATTRIBUTE_NAME))
        .and_then(|s| {
            if let Some(i) = s.find('"') {
                if let Some(j) = s.rfind('"') {
                    return Version::parse(&s[i + 1..j]).ok();
                }
            }
            None
        })
        .ok_or_else(|| {
            anyhow!(
                "valid {} not found in {}",
                VERSION_ATTRIBUTE_NAME,
                path.display()
            )
        })
}

fn version_req(path: &PathBuf) -> Result<(VersionReq, Version)> {
    let version = read_version_attribute(path)?;
    let req = format!(">={}.{}", version.major, version.minor);
    VersionReq::parse(&req)
        .context(format!("parse {} found in {}", req, path.display()))
        .map_err(anyhow::Error::from)
        .map(|req| (req, version))
}

fn write_to_file(path: &PathBuf, rendered: &str, overwrite: &bool) -> Result<()> {
    if !overwrite && path.exists() {
        let (vers_req, ver) = version_req(path)?;
        if !vers_req.matches(&version()) {
            let mut message = format!(
                colorify!(red_bold: "Version requirement {} [{}]\n"),
                vers_req, ver
            );
            message.push_str(&format!(
                colorify!(red: "Your cargo2nix version is {}, whereas the file '{}' was generated by a newer version of cargo2nix.\n"),
                version(),
                path.display()
            ));
            message.push_str(&format!(
                colorify!(red: "Please upgrade your cargo2nix ({}) to proceed."),
                vers_req
            ));
            return Err(anyhow!("{}", message));
        }

        println!(
            colorify!(green_bold: "Version {} matches the requirement {} [{}]"),
            version(),
            vers_req,
            ver
        );
        print!(
            "warning: do you want to overwrite '{}'? yes/no: ",
            path.display()
        );

        io::stdout().flush()?;
        let mut line = String::new();
        io::stdin().read_line(&mut line)?;
        if line.trim() != "yes" {
            println!("aborted!");
            return Ok(());
        }
    }

    let mut temp_file = tempfile::Builder::new()
        .tempfile()
        .context("could not create new temporary file")?;

    write!(temp_file, "{}", rendered)?;

    if let Err(err) = temp_file.persist(path) {
        let (_, temp_path) = err.file.keep()?;
        std::fs::copy(temp_path, path)
            .context(format!("could not write file to {}", path.display()))?;
    }

    Ok(())
}

fn write_to_stdout(rendered: &str) -> Result<()> {
    write!(io::stdout().lock(), "{}", rendered)?;
    Ok(())
}

fn generate_cargo_nix(workspace_directory: &PathBuf, locked: bool) -> Result<String> {
    let mut root_manifest_path = workspace_directory.join("Cargo.toml");

    let metadata = cargo_metadata::MetadataCommand::new()
        .manifest_path(&root_manifest_path)
        .exec()
        .context("Error running cargo metadata")?;
    let resolve = metadata
        .resolve
        .as_ref()
        .context("`resolve` not found - should not happen because we didn't call with --no-deps")?;
    if metadata.workspace_root.as_path() != workspace_directory {
        // In case the caller is running that targeting a subproject instead of the workspace,
        // because metadata resolves the entire workspace
        root_manifest_path = metadata.workspace_root.as_std_path().join("Cargo.toml");
    }

    // Setup ability to lookup packages/targets by id/name
    let mut targets_by_id_and_name: HashMap<
        (&cargo_metadata::PackageId, &str),
        (&cargo_metadata::Package, &cargo_metadata::Target),
    > = HashMap::new();
    for pkg in metadata.packages.iter() {
        for target in pkg.targets.iter() {
            if targets_by_id_and_name
                .insert((&pkg.id, target.name.as_str()), (pkg, target))
                .is_some()
            {
                return Err(anyhow!(
                    "Duplicate target {} in package {}",
                    target.name,
                    pkg.id
                ));
            }
        }
    }
    let get_target = |id: &cargo_metadata::PackageId,
                      name: &str|
     -> anyhow::Result<(&cargo_metadata::Package, &cargo_metadata::Target)> {
        targets_by_id_and_name
            .get(&(id, name))
            .copied()
            .ok_or_else(|| anyhow!("Lost target"))
    };
    let packages_by_id: HashMap<&cargo_metadata::PackageId, &cargo_metadata::Package> =
        metadata.packages.iter().map(|pkg| (&pkg.id, pkg)).collect();
    let get_package = |id: &cargo_metadata::PackageId| -> anyhow::Result<&cargo_metadata::Package> {
        packages_by_id
            .get(id)
            .copied()
            .ok_or_else(|| anyhow!("Lost package"))
    };

    let package_resolve_nodes_by_id: HashMap<&cargo_metadata::PackageId, &cargo_metadata::Node> =
        resolve.nodes.iter().map(|node| (&node.id, node)).collect();

    // Construct ResolvedPackage, which represents a Package with all additional information
    // needed to generate the corresponding nix expression
    let resolved_packages: HashMap<&cargo_metadata::PackageId, &cargo_metadata::Package> = resolve
        .nodes
        .iter()
        .map(|package_resolve_node| {
            let pkg = get_package(&package_resolve_node.id)?;
            // Establish ability to lookup dependencies from the crate name, so that when reading
            // the dependency graph (that only contains the crate name) we can lookup the
            // dependency's activation features
            let crate_ified_dep_names = pkg
                .dependencies
                .iter()
                .map(|dep| {
                    // Yes that is litterally all there is to it
                    // https://docs.rs/cargo/0.75.1/src/cargo/core/manifest.rs.html#793-795
                    dep.rename.as_deref().unwrap_or(&dep.name).replace("-", "_")
                })
                .collect::<Vec<_>>();
            let dependencies_by_crate_name_and_kind: HashMap<
                (&str, cargo_metadata::DependencyKind),
                &cargo_metadata::Dependency,
            > = HashMap::new();
            for (dep, dep_crate_name) in pkg.dependencies.iter().zip(&crate_ified_dep_names) {
                if dependencies_by_crate_name_and_kind
                    .insert((dep_crate_name.as_str(), dep.kind), dep)
                    .is_some()
                {
                    return Err(anyhow!(
                        "Duplicate dependency crate name {} in package {}",
                        dep.name,
                        pkg.id
                    ));
                }
            }
            // Now that we can lookup information about a dependency from the crate name,
            // build a ResolvedDependency that contains all the information needed to generate
            // the corresponding nix expression
            let deps: Vec<ResolvedDependency> = package_resolve_node
                .deps
                .iter()
                .flat_map(|node_dep| {
                    node_dep.dep_kinds.iter().map(|dep_kind| {
                        let dep = *dependencies_by_crate_name_and_kind
                            .get(&(node_dep.name.as_str(), dep_kind.kind))
                            .ok_or_else(|| anyhow!("Lost dependency"))?;
                        Ok(ResolvedDependency {
                            dependency_name: dep.rename.as_deref().unwrap_or(&dep.name),
                            crate_name: &node_dep.name,
                            pkg: get_package(&node_dep.pkg)?,
                            optionality: if dep.optional {
                                Optionality::Optional {
                                    activated_by_local_features: Default::default(),
                                    activated_by_features: Default::default(),
                                }
                            } else {
                                Optionality::Required
                            },
                            dep_kind,
                        })
                    })
                })
                .collect::<Result<Vec<_>>>()?;
            let mut optional_deps_by_name: HashMap<&str, Vec<&mut ResolvedDependency>> =
                HashMap::new();
            for rd in &mut deps {
                if let Optionality::Optional { .. } = rd.optionality {
                    optional_deps_by_name
                        .entry(rd.crate_name)
                        .or_default()
                        .push(rd);
                }
            }
            let features = pkg
                .features
                .keys()
                .map(|feature_name| ResolvedFeature {
                    name: feature_name,
                    optionality: Optionality::Optional {
                        activated_by_local_features: Default::default(),
                        activated_by_features: Default::default(),
                    },
                })
                .collect();
            for (feature, activates_features) in &pkg.features {}
            Ok(ResolvedPackage {
                pkg,
                deps,
                features,
                checksum: todo!(),
            })
        })
        .collect::<Result<_, _>>()?;

    let config = {
        let mut config = cargo::Config::default()?;
        config.configure(0, false, None, false, locked, false, &None, &[], &[])?;
        config
    };

    let root_manifest_path = find_root_manifest_for_wd(workspace_directory)?;
    let ws = Workspace::new(&root_manifest_path, &config)?;

    if !locked {
        let mut registry = PackageRegistry::new(ws.config())?;
        let mut resolve = resolve_with_previous(
            &mut registry,
            &ws,
            &CliFeatures::new_all(true),
            HasDevUnits::Yes,
            None,
            None,
            &[],
            true,
        )?;
        cargo::ops::write_pkg_lockfile(&ws, &mut resolve)?;
    }

    // To get a list of all packages with all features and dependencies that
    // might be enabled present, we first resolve with all features turned on
    let requested_kinds = CompileKind::from_requested_targets(ws.config(), &[])?;
    let target_data = RustcTargetData::new(&ws, &requested_kinds)?;

    // Resolve entire workspace.
    let specs = Packages::All.to_package_id_specs(&ws)?;
    let force_all = cargo::core::resolver::features::ForceAllTargets::Yes;

    // Note that even with --filter-platform we end up downloading host dependencies as well,
    // as that is the behavior of download_accessible.
    let resolved_all = resolve_ws_with_opts(
        &ws,
        &target_data,
        &requested_kinds,
        &CliFeatures::new_all(true),
        &specs,
        HasDevUnits::Yes,
        force_all,
    )?;

    let pkgs_by_id = resolved_all
        .pkg_set
        .get_many(resolved_all.pkg_set.package_ids())?
        .iter()
        .map(|pkg| (pkg.package_id(), *pkg))
        .collect();

    let mut rpkgs_by_id = resolved_all
        .pkg_set
        .get_many(resolved_all.pkg_set.package_ids())?
        .iter()
        .map(|pkg| {
            ResolvedPackage::new(pkg, &pkgs_by_id, &resolved_all.targeted_resolve)
                .map(|res| (pkg.package_id(), res))
        })
        .collect::<Result<_>>()?;

    // Resolve with just packages but no features turned on.  We can compare
    // with this `Resolve` to detect if turning on a feature made a
    // dependency or feature appear
    let no_features = CliFeatures::from_command_line(
        &[],   // no features
        false, // don't use all features
        false, // don't use default features
    )?;

    let resolved_no_features = resolve_ws_with_opts(
        &ws,
        &target_data,
        &requested_kinds,
        &no_features,
        &specs,
        HasDevUnits::Yes,
        force_all,
    )?
    .targeted_resolve;

    let root_pkgs: Vec<_> = ws.members().collect();

    // using the resolved_no_features Resolve, if a package or feature is
    // turned on, then it doesn't depend on any top-level features. While it
    // could depend on which workspace package is built, we always have to
    // assume that any workspace package could be built and build at least
    // that much.
    mark_required(&resolved_no_features, &mut rpkgs_by_id)?;

    for pkg in root_pkgs.iter() {
        mark_feature_activations(
            pkg,
            &ws,
            &resolved_no_features,
            &mut rpkgs_by_id,
            &target_data,
            &requested_kinds,
        )?;
    }

    // Certain optionality cases are redundant, such as including an optional
    // dependency always activates its feature.  These cases are reduced to
    // Optionality::Required
    simplify_optionality(rpkgs_by_id.values_mut());

    let root_manifest = fs::read_to_string(&root_manifest_path)?;
    let profiles = manifest::extract_profiles(&root_manifest);

    let cargo_lock_path = root_manifest_path.clone().with_file_name("Cargo.lock");
    let mut hasher = Sha256::new();
    io::copy(
        &mut fs::File::open(cargo_lock_path).expect("Does the Cargo.lock file exist?"),
        &mut hasher,
    )?;
    let cargo_lock_hash: String = format!("{:x}", hasher.finalize());
    let plan = BuildPlan::from_items(
        cargo_lock_hash,
        root_pkgs,
        profiles,
        rpkgs_by_id,
        workspace_directory,
    )?;
    let mut tera = Tera::default();
    tera.add_raw_template(
        "Cargo.nix.tera",
        include_str!("../templates/Cargo.nix.tera"),
    )?;
    let context = tera::Context::from_serialize(plan)?;
    let rendered = tera.render("Cargo.nix.tera", &context)?;

    Ok(rendered)
}

fn simplify_optionality<'a, 'b: 'a>(rpkgs: impl IntoIterator<Item = &'a mut ResolvedPackage<'b>>) {
    for rpkg in rpkgs.into_iter() {
        // Dev dependencies can't be optional.
        rpkg.deps
            .iter_mut()
            .filter(|((_, kind), _)| *kind == DepKind::Development)
            .for_each(|(_, d)| d.optionality = Optionality::Required);

        // If a package's dependencies or features are activated identically to
        // the features it is activated by, reduce that dependency or feature
        // logic to required
        // TODO
        // For each package, for each feature & dependency, if optionality is
        // identical between package and feature / dependency, set feature /
        // dependency optionality to required
    }
}

fn is_proc_macro(pkg: &Package) -> bool {
    use cargo::core::{compiler::CrateType, TargetKind};
    pkg.targets()
        .iter()
        .filter_map(|t| match t.kind() {
            TargetKind::Lib(kinds) => Some(kinds.iter()),
            _ => None,
        })
        .flatten()
        .any(|k| *k == CrateType::ProcMacro)
}

/// Traverse the whole dependency graph starting at `pkg` and mark required packages & features.
fn mark_required(
    resolved_no_features: &Resolve,
    rpkgs_by_id: &mut BTreeMap<PackageId, ResolvedPackage>,
) -> Result<()> {
    // Dependencies that are activated, even when no features are activated, must be required.
    for id in resolved_no_features.iter() {
        let rpkg = rpkgs_by_id.get_mut(&id).unwrap();
        for feature in resolved_no_features.features(id).iter() {
            // unwrap doen't fail because it's from resolved_all_features
            *(rpkg.features.get_mut(feature.as_str()).unwrap()) = Optionality::Required;
        }

        for (dep_id, _) in resolved_no_features.deps(id) {
            for dep in rpkg.iter_deps_with_id_mut(dep_id) {
                dep.optionality = Optionality::Required;
            }
        }
    }

    Ok(())
}

/// Traverse the whole dependency graph starting at `pkg` and mark packages &
/// features enabled by each feature of `pkg`.
fn mark_feature_activations<'a>(
    root_pkg: &'a Package,
    ws: &Workspace,
    resolved_no_features: &Resolve,
    rpkgs_by_id: &mut BTreeMap<PackageId, ResolvedPackage<'a>>,
    target_data: &RustcTargetData,
    compile_kinds: &[CompileKind],
) -> Result<()> {
    let root_pkg_name = root_pkg.name().as_str();
    let root_pkg_features = root_pkg.summary().features();

    let spec = PackageIdSpec::from_package_id(root_pkg.package_id());

    for feature in root_pkg_features.keys() {
        // resolve ws with just the target feature activated
        let just_this_feature = CliFeatures::from_command_line(
            &[feature.to_string()], // just the active feature
            false,                  // don't use all features
            false,                  // don't use default features
        )?;

        let just_feature_ws = resolve_ws_with_opts(
            ws,
            &target_data,
            &compile_kinds,
            &just_this_feature,
            &[spec.clone()],
            HasDevUnits::Yes,
            ForceAllTargets::Yes,
        )?;

        for rpkg in rpkgs_by_id.values_mut() {
            let deps_no_features: HashSet<_> = resolved_no_features
                .deps(rpkg.pkg.package_id())
                .map(|(dep, _)| dep)
                .collect();

            let deps_just_feature: HashSet<_> = just_feature_ws
                .targeted_resolve
                .deps(rpkg.pkg.package_id())
                .map(|(dep, _)| dep)
                .collect();

            rpkg.deps
                .iter_mut()
                .map(|(_, rpkg)| rpkg)
                .filter(|rpkg| {
                    !deps_no_features.contains(&rpkg.pkg.package_id())
                        && deps_just_feature.contains(&rpkg.pkg.package_id())
                })
                .for_each(|rpkg| rpkg.optionality.activated_by((root_pkg_name, feature)));

            let features_no_features: HashSet<_> = resolved_no_features
                .features(rpkg.pkg.package_id())
                .iter()
                .map(|feature| feature.to_string())
                .collect();

            let features_just_feature: HashSet<_> = just_feature_ws
                .targeted_resolve
                .features(rpkg.pkg.package_id())
                .iter()
                .map(|feature| feature.to_string())
                .collect();

            rpkg.features
                .iter_mut()
                .filter(|(f, _)| {
                    !features_no_features.contains(&f.to_string())
                        && features_just_feature.contains(&f.to_string())
                })
                .for_each(|(_f, optionality)| optionality.activated_by((root_pkg_name, feature)));
        }
    }

    Ok(())
}

#[derive(Debug)]
pub struct ResolvedPackage<'a> {
    pkg: &'a cargo_metadata::Package,
    deps: Vec<ResolvedDependency<'a>>,
    features: Vec<ResolvedFeature<'a>>,
    checksum: Option<&'a str>,
}

impl<'a> ResolvedPackage<'a> {
    fn new(
        pkg: &'a Package,
        pkgs_by_id: &HashMap<PackageId, &'a Package>,
        resolve: &'a Resolve,
    ) -> Result<Self> {
        let mut deps = BTreeMap::new();
        resolve
            .deps(pkg.package_id())
            .filter_map(|(dep_id, deps)| {
                let dep_pkg = pkgs_by_id[&dep_id];
                let extern_name = resolve
                    .extern_crate_name_and_dep_name(
                        pkg.package_id(),
                        dep_id,
                        dep_pkg.targets().iter().find(|t| t.is_lib())?,
                    )
                    .ok()?
                    .0
                    .to_string();

                Some(
                    deps.iter()
                        .map(move |dep| (dep_id, dep, dep_pkg, extern_name.clone())),
                )
            })
            .flatten()
            .for_each(|(dep_id, dep, dep_pkg, extern_name)| {
                let rdep = deps
                    .entry((dep_id, dep.kind()))
                    .or_insert(ResolvedDependency {
                        crate_name: extern_name,
                        pkg: dep_pkg,
                        optionality: Optionality::default(),
                        platforms: Some(BTreeSet::new()),
                    });

                match (dep.platform(), rdep.platforms.as_mut()) {
                    (Some(platform), Some(platforms)) => {
                        platforms.insert(platform);
                    }
                    (None, _) => rdep.platforms = None,
                    _ => {}
                }
            });

        let features = resolve
            .features(pkg.package_id())
            .iter()
            .map(|feature| (feature.as_str(), Optionality::default()))
            .collect();

        let checksum = resolve
            .checksums()
            .get(&pkg.package_id())
            .and_then(|opt| opt.as_ref().map(|s| s.as_str()));

        Ok(Self {
            pkg,
            deps,
            features,
            checksum,
        })
    }

    fn iter_deps_with_id_mut(
        &mut self,
        id: PackageId,
    ) -> impl Iterator<Item = &mut ResolvedDependency<'a>> {
        self.deps
            .range_mut((id, DepKind::Normal)..=(id, DepKind::Build))
            .map(|(_, dep)| dep)
    }
}

#[derive(Debug)]
struct ResolvedDependency<'a> {
    dependency_name: &'a str,
    crate_name: &'a str,
    pkg: &'a cargo_metadata::Package,
    optionality: Optionality<'a>,
    dep_kind: &'a cargo_metadata::DepKindInfo,
}

#[derive(Debug)]
struct ResolvedFeature<'a> {
    name: &'a str,
    optionality: Optionality<'a>,
}

#[derive(PartialEq, Eq, Debug)]
enum Optionality<'a> {
    Required,
    Optional {
        activated_by_local_features: HashSet<&'a str>,
        activated_by_features: HashSet<RootFeature<'a>>,
    },
}

impl<'a> Default for Optionality<'a> {
    fn default() -> Self {
        Optionality::Optional {
            activated_by_features: Default::default(),
        }
    }
}

impl<'a> Optionality<'a> {
    fn activated_by(&mut self, (root_pkg_name, feature): RootFeature<'a>) {
        if let Optionality::Optional {
            activated_by_features,
        } = self
        {
            activated_by_features.insert((root_pkg_name, feature));
        }
    }

    fn to_expr(&self, root_features_var: &str) -> BoolExpr {
        use self::BoolExpr::*;

        match self {
            Optionality::Required => True,
            Optionality::Optional {
                activated_by_features,
            } => BoolExpr::ors(activated_by_features.iter().map(|root_feature| {
                Single(format!(
                    "{} ? {:?}",
                    root_features_var,
                    display_root_feature(*root_feature)
                ))
            })),
        }
    }
}

fn display_root_feature((pkg_name, feature): RootFeature) -> String {
    format!("{}/{}", pkg_name, feature)
}
